{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import transform\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "import utils\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_relabels(path):\n",
    "    # https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/forums/t/28150/unified-effort-to-relabel-the-training-set\n",
    "    relabels = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            cols = line.split()\n",
    "            src = \"{}/{}/{}.jpg\".format(config.training_images_path, cols[1], cols[0])\n",
    "            relabels[src] = cols[2]\n",
    "    return relabels\n",
    "\n",
    "\n",
    "def read_bbox_annotations(path):\n",
    "    boxes = {}\n",
    "    for c in classes:\n",
    "        path = os.path.join(path, c + '.json')\n",
    "        if os.path.isfile(path):\n",
    "            class_boxes = utils.read_bbox_json(path)\n",
    "            boxes.update(class_boxes)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def preprocess_img_data(img_arr):\n",
    "    preprocess_input(img_arr)\n",
    "\n",
    "\n",
    "def read_training_images(path, boxes, relabels):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    y_train_box = []\n",
    "\n",
    "    t0 = time.time()\n",
    "    print('Reading training images...')\n",
    "\n",
    "    for c in classes:\n",
    "        images = glob.glob(os.path.join(path, c, '*.jpg'))\n",
    "        class_index = classes.index(c)\n",
    "        print('Loading class: {}'.format(c))\n",
    "\n",
    "        for img_path in images:\n",
    "            # print('Reading: ', img_path)\n",
    "            img_name = os.path.basename(img_path)\n",
    "            img = Image.open(img_path)\n",
    "            x_scale = float(config.img_w) / float(img.width)\n",
    "            y_scale = float(config.img_h) / float(img.height)\n",
    "            img = img.resize((config.img_w, config.img_h))\n",
    "\n",
    "            max_box = [0, 0, 0, 0]\n",
    "            # get the largest bbox\n",
    "            if c in boxes and img_name in boxes[c]:\n",
    "                img_boxes = boxes[c][img_name]\n",
    "                max_area = 0\n",
    "                for box in img_boxes:\n",
    "                    box_area = box[2] * box[3]\n",
    "                    if box_area > max_area:\n",
    "                        max_area = box_area\n",
    "                        max_box = box\n",
    "\n",
    "            max_box[0] *= x_scale\n",
    "            max_box[1] *= y_scale\n",
    "            max_box[2] *= x_scale\n",
    "            max_box[3] *= y_scale\n",
    "\n",
    "            add_img = True\n",
    "            img_class = class_index\n",
    "            if img_path in relabels:\n",
    "                if relabels[img_path] == 'revise':\n",
    "                    add_img = False\n",
    "                    print('Image omitted: ', img_path)\n",
    "                else:\n",
    "                    print('Label revised: ', img_path, relabels[img_path])\n",
    "                    img_class = classes.index(relabels[img_path])\n",
    "\n",
    "            if add_img:\n",
    "                X_train.append(np.asarray(img, dtype=np.uint8))\n",
    "                y_train.append(img_class)\n",
    "                y_train_box.append(max_box)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train, dtype=np.uint8)\n",
    "    y_train = np_utils.to_categorical(y_train, 8)\n",
    "    y_train_box = np.array(y_train_box, dtype=np.float32)\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('Reading finished: {} seconds'.format(round(t1 - t0, 2)))\n",
    "    print('Training data shape:', X_train.shape)\n",
    "    return X_train, y_train, y_train_box\n",
    "\n",
    "\n",
    "def read_testing_images(path):\n",
    "    X_test = []\n",
    "    Id_test = []\n",
    "\n",
    "    print('Reading testing data...')\n",
    "    t0 = time.time()\n",
    "    images = glob.glob(os.path.join(path, '*.jpg'))\n",
    "\n",
    "    for img_path in images:\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((config.img_w, config.img_h), Image.ANTIALIAS)\n",
    "        X_test.append(np.asarray(img, dtype=np.float32))\n",
    "        Id_test.append(os.path.basename(img_path))\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    Id_test = np.array(Id_test)\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('Reading finished: {} seconds'.format(round(t1 - t0, 2))) \n",
    "    print('Test data shape:', X_test.shape)\n",
    "    return X_test, Id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot(img):\n",
    "    x = copy.copy(img)\n",
    "    '''\n",
    "    x = x + max(-np.min(x), 0)\n",
    "    x_max = np.max(x)\n",
    "    if x_max != 0:\n",
    "        x /= x_max\n",
    "    x *= 255\n",
    "    '''\n",
    "    plt.imshow(np.array(x, dtype=np.uint8))\n",
    "\n",
    "\n",
    "\n",
    "def plot_box(a, b, c, d):\n",
    "    ax = plt.gca()\n",
    "    ax.text(a[0], a[1], 'P0', color='yellow')\n",
    "    ax.text(b[0], b[1], 'P1', color='yellow')\n",
    "    ax.text(c[0], c[1], 'P2', color='yellow')\n",
    "    ax.text(d[0], d[1], 'P3', color='yellow')\n",
    "    ax.plot(a[0], a[1], 'o', color='red')\n",
    "    ax.plot(b[0], b[1], 'o', color='red')\n",
    "    ax.plot(c[0], c[1], 'o', color='red')\n",
    "    ax.plot(d[0], d[1], 'o', color='red')\n",
    "    \n",
    "    ax.plot([a[0], b[0]], [a[1], b[1]], color='green')\n",
    "    ax.plot([b[0], c[0]], [b[1], c[1]], color='green')\n",
    "    ax.plot([c[0], d[0]], [c[1], d[1]], color='green')\n",
    "    ax.plot([d[0], a[0]], [d[1], a[1]], color='green')\n",
    "\n",
    "\n",
    "def create_rect_xywh(box, color='red'):\n",
    "    return plt.Rectangle((box[0], box[1]), box[2], box[3],\n",
    "                         color=color, fill=False, linewidth=2)\n",
    "\n",
    "def plot_bb(img, bb):\n",
    "    plt.figure(figsize=(9, 12))\n",
    "    plot(img)\n",
    "    ax = plt.gca()\n",
    "    print('Box (x,y,w,h): ', bb)\n",
    "    if bb[2] > 0 and bb[3] > 0:\n",
    "        ax.add_patch(create_rect_xywh(bb, 'yellow'))\n",
    "        \n",
    "\n",
    "def rotation(angle):\n",
    "    return np.array([[np.cos(angle), -np.sin(angle), 0],\n",
    "                     [np.sin(angle), np.cos(angle), 0],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "\n",
    "def translation(x, y):\n",
    "    return np.array([[1, 0, x],\n",
    "                     [0, 1, y],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "\n",
    "def scale(sx, sy):\n",
    "    return np.array([[sx, 0, 0],\n",
    "                     [0, sy, 0],\n",
    "                     [0, 0,  1]])\n",
    "\n",
    "    \n",
    "def box_zoom_rotate_translate(img, bb, x_scale_range,\n",
    "                              y_scale_range, rotation_range,\n",
    "                              translation_range, mode='edge'):\n",
    "    \"\"\"Performs zoom of a Numpy image tensor.\n",
    "    # Arguments\n",
    "        img: Input image tensor (w, h, c).\n",
    "        bb: Bounding box tuple/array [x, y, w, h]\n",
    "        x_scale_range: [1, sx]: x scale range.\n",
    "        y_scale_range: [1, sy]: y scale range.\n",
    "        rotation_range: Rotation range.\n",
    "        translation_range: Translation range.\n",
    "        mode: \n",
    "    # Returns\n",
    "        Zoomed, rotated and translated numpy image tensor (w, h, c).\n",
    "        New axis aligned bounding box [x, y, w, h].\n",
    "        Transformed original bounding box [[x1,y1], [x2,y2], [x3,y3], [x4,y4]].\n",
    "    # Raises\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    sx = np.random.uniform(1, x_scale_range)\n",
    "    sy = np.random.uniform(1, y_scale_range)\n",
    "    theta = np.random.uniform(-rotation_range, rotation_range)\n",
    "    rtx = np.random.uniform(-translation_range, translation_range)\n",
    "    rty = np.random.uniform(-translation_range, translation_range)\n",
    "    \n",
    "    # zoom center\n",
    "    zcx = (bb[0] + bb[2] / 2.0 + 0.5)\n",
    "    zcy = (bb[1] + bb[3] / 2.0 + 0.5)\n",
    "    \n",
    "    # box top left\n",
    "    box_tl = [bb[0], bb[1], 1]\n",
    "    # box bottom right\n",
    "    box_br = [bb[0] + bb[2], bb[1] + bb[3], 1]\n",
    "    \n",
    "    # transformation matrices\n",
    "    tm = translation(-zcx, -zcy)\n",
    "    sm = scale(sx, sy)\n",
    "    rm = rotation(-theta)\n",
    "    \n",
    "    # rotate and zoom around the center of bb\n",
    "    t = np.dot(rm, np.dot(sm, tm))\n",
    "    \n",
    "    # calculate zoomed and rotated bounding box\n",
    "    v = np.array([box_br[0] - box_tl[0], 0, 1])\n",
    "    \n",
    "    box_tl = np.dot(t, box_tl)\n",
    "    box_br = np.dot(t, box_br)\n",
    "    v = np.dot(rm, np.dot(sm, v))\n",
    "    \n",
    "    box = np.array([box_tl, box_tl + v, box_br, box_br - v])\n",
    "    \n",
    "    # calculate min and max translation so that the final axis aligned\n",
    "    # box remains inside the image\n",
    "    tl_x = np.min([p[0] for p in box])\n",
    "    tl_y = np.min([p[1] for p in box])\n",
    "    br_x = np.max([p[0] for p in box])\n",
    "    br_y = np.max([p[1] for p in box])\n",
    "    \n",
    "    min_translation = -1 * np.array([tl_x, tl_y])\n",
    "    max_translation = img.shape[:2] - np.array([br_x, br_y])\n",
    "    \n",
    "    # get random translation between min and max\n",
    "    rtx = np.max([min_translation[0], rtx])\n",
    "    rtx = np.min([max_translation[0], rtx])\n",
    "    rty = np.max([min_translation[1], rty])\n",
    "    rty = np.min([max_translation[1], rty])\n",
    "    \n",
    "    t2 = translation(rtx, rty)\n",
    "    \n",
    "    # calculate final axis aligned bounding box\n",
    "    box_tl = np.dot(t2, box_tl)\n",
    "    box_br = np.dot(t2, box_br)\n",
    "    \n",
    "    box = np.array([box_tl, box_tl + v, box_br, box_br - v])\n",
    "    box_tl[0] = np.min([p[0] for p in box])\n",
    "    box_tl[1] = np.min([p[1] for p in box])\n",
    "    box_br[0] = np.max([p[0] for p in box])\n",
    "    box_br[1] = np.max([p[1] for p in box]) \n",
    "\n",
    "    # transform the image\n",
    "    tc = transform.SimilarityTransform(matrix=translation(zcx, zcy))\n",
    "    tz = transform.SimilarityTransform(matrix=scale(1.0 / sx, 1.0 / sy))\n",
    "    tr = transform.SimilarityTransform(matrix=rotation(theta))\n",
    "    tu = transform.SimilarityTransform(matrix=translation(-rtx, -rty))\n",
    "    \n",
    "    img = img_as_ubyte(transform.warp(img, tu + tr + tz + tc, mode=mode))\n",
    "    return img, [box_tl[0], box_tl[1], box_br[0] - box_tl[0], box_br[1] - box_tl[1]], box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxes = read_bbox_annotations(config.bbox_annotations_path)\n",
    "relabels = read_relabels('relabels.csv')\n",
    "\n",
    "X_train, y_train, y_train_box = \\\n",
    "    read_training_images(config.training_images_path, boxes, relabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training data...\n"
     ]
    }
   ],
   "source": [
    "print('Saving training data...')\n",
    "utils.save_array('X_train.bcolz', X_train)\n",
    "utils.save_array('y_train.bcolz', y_train)\n",
    "utils.save_array('y_train_box.bcolz', y_train_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: 1.1808175151407987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: -2.336895399346322\n",
      "(3768, 448, 448, 3)\n",
      "(3768, 8)\n",
      "(3767, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Augmenting training data...')\n",
    "# extend training set\n",
    "factor = 10\n",
    "rotation_range = 2 * np.pi\n",
    "x_scale_range = 1.2\n",
    "y_scale_range = 1.2\n",
    "translation_range = 50\n",
    "\n",
    "n = len(X_train)\n",
    "total = n * factor\n",
    "cnt = 0\n",
    "last_percent = 0\n",
    "\n",
    "for i in range(n):\n",
    "    c = y_train[i]\n",
    "    for k in range(factor):\n",
    "        img, a_bb, t_bb = box_zoom_rotate_translate(X_train[i],\n",
    "                                                    y_train_box[i],\n",
    "                                                    x_scale_range,\n",
    "                                                    y_scale_range,\n",
    "                                                    rotation_range,\n",
    "                                                    translation_range)\n",
    "        X_train = np.append(X_train, [img], axis=0)\n",
    "        y_train = np.append(y_train, [c], axis=0)\n",
    "        \n",
    "        # append dummy bbox if there isn't any give for this image\n",
    "        if y_train_box[i][2] == 0 and y_tran_box[i][3] == 0:\n",
    "            y_train_box = np.append(y_train_box, [[0, 0, 0, 0]], axis=0)\n",
    "        else:\n",
    "            y_train_box = np.append(y_train_box, [a_bb], axis=0)\n",
    "        \n",
    "        cnt += 1\n",
    "        percent = int(cnt / (total / 100.0))\n",
    "        if percent != last_percent:\n",
    "            print('progress: {}%'.format(precent))\n",
    "            last_percent = percent\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_train_box:', y_train_box.shape)\n",
    "utils.save_array('X_train_augmented.bcolz', X_train)\n",
    "utils.save_array('y_train_augmented.bcolz', y_train)\n",
    "utils.save_array('y_train_box_augmented.bcolz', y_train_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f13f100197ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mId_test\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0mread_testing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting_images_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-84389aff91f0>\u001b[0m in \u001b[0;36mread_testing_images\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mId_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample)\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBa'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEAREST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_test, Id_test = \\\n",
    "    read_testing_images(config.testing_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Preprocessing X_train...')\n",
    "vgg = create_vgg(config.img_w, config.img_h)\n",
    "X_train_feat = predict(X_train, vgg, 8)\n",
    "\n",
    "print('Preprocessing X_test...')\n",
    "X_test_feat = predict(X_test, vgg, 8)\n",
    "\n",
    "utils.save_array('X_train_feat.bcolz', X_train_feat)\n",
    "utils.save_array('X_test_feat.bcolz', X_test_feat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
