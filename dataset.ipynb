{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "import utils\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "np.random.seed(config.random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_relabels(path):\n",
    "    # https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/forums/t/28150/unified-effort-to-relabel-the-training-set\n",
    "    relabels = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            cols = line.split()\n",
    "            src = \"{}/{}/{}.jpg\".format(config.training_images_path, cols[1], cols[0])\n",
    "            relabels[src] = cols[2]\n",
    "    return relabels\n",
    "\n",
    "\n",
    "def read_bbox_annotations(path):\n",
    "    boxes = {}\n",
    "    for c in classes:\n",
    "        path = os.path.join(path, c + '.json')\n",
    "        if os.path.isfile(path):\n",
    "            class_boxes = utils.read_bbox_json(path)\n",
    "            boxes.update(class_boxes)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def preprocess_img_data(img_arr):\n",
    "    preprocess_input(img_arr)\n",
    "\n",
    "\n",
    "def read_training_images(path, boxes, relabels):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    y_train_box = []\n",
    "\n",
    "    t0 = time.time()\n",
    "    print('Reading training images...')\n",
    "\n",
    "    for c in classes:\n",
    "        images = glob.glob(os.path.join(path, c, '*.jpg'))\n",
    "        class_index = classes.index(c)\n",
    "        print('Loading class: {}'.format(c))\n",
    "\n",
    "        for img_path in images:\n",
    "            # print('Reading: ', img_path)\n",
    "            img_name = os.path.basename(img_path)\n",
    "            img = Image.open(img_path)\n",
    "            x_scale = float(config.img_w) / float(img.width)\n",
    "            y_scale = float(config.img_h) / float(img.height)\n",
    "            img = img.resize((config.img_w, config.img_h))\n",
    "\n",
    "            max_box = [0, 0, 0, 0]\n",
    "            # get the largest bbox\n",
    "            if c in boxes and img_name in boxes[c]:\n",
    "                img_boxes = boxes[c][img_name]\n",
    "                max_area = 0\n",
    "                for box in img_boxes:\n",
    "                    box_area = box[2] * box[3]\n",
    "                    if box_area > max_area:\n",
    "                        max_area = box_area\n",
    "                        max_box = box\n",
    "\n",
    "            max_box[0] *= x_scale\n",
    "            max_box[1] *= y_scale\n",
    "            max_box[2] *= x_scale\n",
    "            max_box[3] *= y_scale\n",
    "\n",
    "            add_img = True\n",
    "            img_class = class_index\n",
    "            if img_path in relabels:\n",
    "                if relabels[img_path] == 'revise':\n",
    "                    add_img = False\n",
    "                    print('Image omitted: ', img_path)\n",
    "                else:\n",
    "                    print('Label revised: ', img_path, relabels[img_path])\n",
    "                    img_class = classes.index(relabels[img_path])\n",
    "\n",
    "            if add_img:\n",
    "                X_train.append(np.asarray(img, dtype=np.uint8))\n",
    "                y_train.append(img_class)\n",
    "                y_train_box.append(max_box)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train, dtype=np.uint8)\n",
    "    y_train = np_utils.to_categorical(y_train, 8)\n",
    "    y_train_box = np.asarray(y_train_box, dtype=np.float32)\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('Reading finished: {} seconds'.format(round(t1 - t0, 2)))\n",
    "    print('Training data shape:', X_train.shape)\n",
    "    return X_train, y_train, y_train_box\n",
    "\n",
    "\n",
    "def read_testing_images(path):\n",
    "    X_test = []\n",
    "    Id_test = []\n",
    "\n",
    "    print('Reading testing data...')\n",
    "    t0 = time.time()\n",
    "    images = glob.glob(os.path.join(path, '*.jpg'))\n",
    "\n",
    "    for img_path in images:\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((config.img_w, config.img_h), Image.ANTIALIAS)\n",
    "        X_test.append(np.asarray(img, dtype=np.float32))\n",
    "        Id_test.append(os.path.basename(img_path))\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    Id_test = np.array(Id_test)\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('Reading finished: {} seconds'.format(round(t1 - t0, 2))) \n",
    "    print('Test data shape:', X_test.shape)\n",
    "    return X_test, Id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot(img):\n",
    "    x = copy.copy(img)\n",
    "    '''\n",
    "    x = x + max(-np.min(x), 0)\n",
    "    x_max = np.max(x)\n",
    "    if x_max != 0:\n",
    "        x /= x_max\n",
    "    x *= 255\n",
    "    '''\n",
    "    plt.imshow(np.array(x, dtype=np.uint8))\n",
    "\n",
    "\n",
    "\n",
    "def plot_box(a, b, c, d):\n",
    "    ax = plt.gca()\n",
    "    ax.text(a[0], a[1], 'P0', color='yellow')\n",
    "    ax.text(b[0], b[1], 'P1', color='yellow')\n",
    "    ax.text(c[0], c[1], 'P2', color='yellow')\n",
    "    ax.text(d[0], d[1], 'P3', color='yellow')\n",
    "    ax.plot(a[0], a[1], 'o', color='red')\n",
    "    ax.plot(b[0], b[1], 'o', color='red')\n",
    "    ax.plot(c[0], c[1], 'o', color='red')\n",
    "    ax.plot(d[0], d[1], 'o', color='red')\n",
    "    \n",
    "    ax.plot([a[0], b[0]], [a[1], b[1]], color='green')\n",
    "    ax.plot([b[0], c[0]], [b[1], c[1]], color='green')\n",
    "    ax.plot([c[0], d[0]], [c[1], d[1]], color='green')\n",
    "    ax.plot([d[0], a[0]], [d[1], a[1]], color='green')\n",
    "\n",
    "\n",
    "def create_rect_xywh(box, color='red'):\n",
    "    return plt.Rectangle((box[0], box[1]), box[2], box[3],\n",
    "                         color=color, fill=False, linewidth=2)\n",
    "\n",
    "def plot_bb(img, bb):\n",
    "    plt.figure(figsize=(9, 12))\n",
    "    plot(img)\n",
    "    ax = plt.gca()\n",
    "    print('Box (x,y,w,h): ', bb)\n",
    "    if bb[2] > 0 and bb[3] > 0:\n",
    "        ax.add_patch(create_rect_xywh(bb, 'yellow'))\n",
    "        \n",
    "\n",
    "def rotation(angle):\n",
    "    return np.array([[np.cos(angle), -np.sin(angle), 0],\n",
    "                     [np.sin(angle), np.cos(angle), 0],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "\n",
    "def translation(x, y):\n",
    "    return np.array([[1, 0, x],\n",
    "                     [0, 1, y],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "\n",
    "def scale(sx, sy):\n",
    "    return np.array([[sx, 0, 0],\n",
    "                     [0, sy, 0],\n",
    "                     [0, 0,  1]])\n",
    "\n",
    "\n",
    "def box_zoom_rotate_translate(img, bb, x_scale_range,\n",
    "                              y_scale_range, rotation_range,\n",
    "                              translation_range, mode='edge'):\n",
    "    \"\"\"Performs zoom of a Numpy image tensor.\n",
    "    # Arguments\n",
    "        img: Input image tensor (w, h, c).\n",
    "        bbox: Bounding box tuple/array [x, y, w, h]\n",
    "        x_scale_range: [1, sx]: x scale range.\n",
    "        y_scale_range: [1, sy]: y scale range.\n",
    "        rotation_range: Rotation range.\n",
    "        translation_range: Translation range.\n",
    "        mode: \n",
    "    # Returns\n",
    "        Zoomed, rotated and translated numpy image tensor (w, h, c).\n",
    "        New axis aligned bounding box [x, y, w, h].\n",
    "        Transformed original bounding box [[x1,y1], [x2,y2], [x3,y3], [x4,y4]].\n",
    "    # Raises\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    sx = np.random.uniform(1, x_scale_range)\n",
    "    sy = np.random.uniform(1, y_scale_range)\n",
    "    theta = np.random.uniform(-rotation_range, rotation_range)\n",
    "    rtx = np.random.uniform(-translation_range, translation_range)\n",
    "    rty = np.random.uniform(-translation_range, translation_range)\n",
    "    \n",
    "    if bb[2] == 0 and bb[3] == 0:\n",
    "        zcx = (img.shape[0] / 2.0)\n",
    "        zcy = (img.shape[1] / 2.0)\n",
    "        rtx = zcx - rtx\n",
    "        rty = zcy - rty\n",
    "        box_tl = [0, 0]\n",
    "        box_br = [0, 0]\n",
    "        box = [0, 0, 0, 0]\n",
    "    else:\n",
    "        # zoom center\n",
    "        zcx = (bb[0] + bb[2] / 2.0)\n",
    "        zcy = (bb[1] + bb[3] / 2.0)\n",
    "\n",
    "        # box top left\n",
    "        box_tl = [bb[0], bb[1], 1]\n",
    "        # box bottom right\n",
    "        box_br = [bb[0] + bb[2], bb[1] + bb[3], 1]\n",
    "\n",
    "        # transformation matrices\n",
    "        tm = translation(-zcx, -zcy)\n",
    "        sm = scale(sx, sy)\n",
    "        rm = rotation(-theta)\n",
    "\n",
    "        # rotate and zoom around the center of bb\n",
    "        t = np.dot(rm, np.dot(sm, tm))\n",
    "\n",
    "        # calculate zoomed and rotated bounding box\n",
    "        v = np.array([box_br[0] - box_tl[0], 0, 1])\n",
    "\n",
    "        box_tl = np.dot(t, box_tl)\n",
    "        box_br = np.dot(t, box_br)\n",
    "        v = np.dot(rm, np.dot(sm, v))\n",
    "\n",
    "        box = np.array([box_tl, box_tl + v, box_br, box_br - v])\n",
    "\n",
    "        # calculate min and max translation so that the final axis aligned\n",
    "        # box remains inside the image\n",
    "        tl_x = np.min([p[0] for p in box])\n",
    "        tl_y = np.min([p[1] for p in box])\n",
    "        br_x = np.max([p[0] for p in box])\n",
    "        br_y = np.max([p[1] for p in box])\n",
    "        \n",
    "        min_translation = -1 * np.array([tl_x, tl_y])\n",
    "        max_translation = img.shape[:2] - np.array([br_x, br_y])\n",
    "\n",
    "        # get random translation between min and max\n",
    "        rtx += zcx\n",
    "        rty += zcy\n",
    "        rtx = np.max([min_translation[0], rtx])\n",
    "        rtx = np.min([max_translation[0], rtx])\n",
    "\n",
    "        rty = np.max([min_translation[1], rty])\n",
    "        rty = np.min([max_translation[1], rty])\n",
    "    \n",
    "        t2 = translation(rtx, rty)\n",
    "\n",
    "        # calculate final axis aligned bounding box\n",
    "        box_tl = np.dot(t2, box_tl)\n",
    "        box_br = np.dot(t2, box_br)\n",
    "\n",
    "        box = np.array([box_tl, box_tl + v, box_br, box_br - v])\n",
    "        box_tl[0] = np.min([p[0] for p in box])\n",
    "        box_tl[1] = np.min([p[1] for p in box])\n",
    "        box_br[0] = np.max([p[0] for p in box])\n",
    "        box_br[1] = np.max([p[1] for p in box])\n",
    "\n",
    "    # transform the image\n",
    "    tc = transform.SimilarityTransform(matrix=translation(zcx, zcy))\n",
    "    tz = transform.SimilarityTransform(matrix=scale(1.0 / sx, 1.0 / sy))\n",
    "    tr = transform.SimilarityTransform(matrix=rotation(theta))\n",
    "    tu = transform.SimilarityTransform(matrix=translation(-rtx, -rty))\n",
    "    \n",
    "    img = img_as_ubyte(transform.warp(img, tu + tr + tz + tc, mode=mode)) \n",
    "    return img, [box_tl[0], box_tl[1], box_br[0] - box_tl[0], box_br[1] - box_tl[1]], box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training images...\n",
      "Loading class: ALB\n",
      "Label revised:  train/ALB/img_02086.jpg YFT\n",
      "Label revised:  train/ALB/img_00248.jpg OTHER\n",
      "Label revised:  train/ALB/img_01363.jpg OTHER\n",
      "Label revised:  train/ALB/img_00568.jpg NoF\n",
      "Loading class: BET\n",
      "Loading class: DOL\n",
      "Image omitted:  train/DOL/img_07212.jpg\n",
      "Loading class: LAG\n",
      "Loading class: NoF\n",
      "Image omitted:  train/NoF/img_01989.jpg\n",
      "Image omitted:  train/NoF/img_03386.jpg\n",
      "Label revised:  train/NoF/img_06031.jpg ALB\n",
      "Label revised:  train/NoF/img_06675.jpg ALB\n",
      "Label revised:  train/NoF/img_07724.jpg YFT\n",
      "Label revised:  train/NoF/img_04847.jpg ALB\n",
      "Label revised:  train/NoF/img_02325.jpg BET\n",
      "Label revised:  train/NoF/img_04590.jpg ALB\n",
      "Label revised:  train/NoF/img_00076.jpg ALB\n",
      "Label revised:  train/NoF/img_04615.jpg ALB\n",
      "Label revised:  train/NoF/img_00904.jpg ALB\n",
      "Label revised:  train/NoF/img_00028.jpg ALB\n",
      "Label revised:  train/NoF/img_02621.jpg ALB\n",
      "Label revised:  train/NoF/img_06266.jpg YFT\n",
      "Label revised:  train/NoF/img_02302.jpg ALB\n",
      "Label revised:  train/NoF/img_03949.jpg BET\n",
      "Image omitted:  train/NoF/img_06478.jpg\n",
      "Label revised:  train/NoF/img_02044.jpg ALB\n",
      "Label revised:  train/NoF/img_03173.jpg YFT\n",
      "Label revised:  train/NoF/img_00819.jpg YFT\n",
      "Image omitted:  train/NoF/img_07268.jpg\n",
      "Label revised:  train/NoF/img_07847.jpg ALB\n",
      "Label revised:  train/NoF/img_05865.jpg YFT\n",
      "Label revised:  train/NoF/img_00673.jpg ALB\n",
      "Label revised:  train/NoF/img_02232.jpg SHARK\n",
      "Label revised:  train/NoF/img_01120.jpg ALB\n",
      "Label revised:  train/NoF/img_04162.jpg ALB\n",
      "Image omitted:  train/NoF/img_04052.jpg\n",
      "Label revised:  train/NoF/img_07100.jpg ALB\n",
      "Loading class: OTHER\n",
      "Label revised:  train/OTHER/img_04880.jpg ALB\n",
      "Label revised:  train/OTHER/img_00485.jpg ALB\n",
      "Label revised:  train/OTHER/img_04948.jpg ALB\n",
      "Label revised:  train/OTHER/img_01678.jpg ALB\n",
      "Label revised:  train/OTHER/img_06463.jpg ALB\n",
      "Label revised:  train/OTHER/img_05425.jpg ALB\n",
      "Label revised:  train/OTHER/img_06706.jpg ALB\n",
      "Label revised:  train/OTHER/img_06111.jpg ALB\n",
      "Label revised:  train/OTHER/img_06149.jpg ALB\n",
      "Label revised:  train/OTHER/img_07779.jpg ALB\n",
      "Label revised:  train/OTHER/img_06700.jpg ALB\n",
      "Label revised:  train/OTHER/img_04057.jpg ALB\n",
      "Label revised:  train/OTHER/img_04826.jpg ALB\n",
      "Label revised:  train/OTHER/img_02099.jpg ALB\n",
      "Label revised:  train/OTHER/img_01452.jpg LAG\n",
      "Loading class: SHARK\n",
      "Image omitted:  train/SHARK/img_02271.jpg\n",
      "Image omitted:  train/SHARK/img_04131.jpg\n",
      "Loading class: YFT\n",
      "Image omitted:  train/YFT/img_00752.jpg\n",
      "Image omitted:  train/YFT/img_02199.jpg\n",
      "Image omitted:  train/YFT/img_01087.jpg\n",
      "Image omitted:  train/YFT/img_01532.jpg\n",
      "Image omitted:  train/YFT/img_02364.jpg\n",
      "Image omitted:  train/YFT/img_01610.jpg\n",
      "Image omitted:  train/YFT/img_01410.jpg\n",
      "Image omitted:  train/YFT/img_00890.jpg\n",
      "Image omitted:  train/YFT/img_01007.jpg\n",
      "Image omitted:  train/YFT/img_00739.jpg\n",
      "Reading finished: 24.49 seconds\n",
      "Training data shape: (3759, 448, 448, 3)\n"
     ]
    }
   ],
   "source": [
    "boxes = read_bbox_annotations(config.bbox_annotations_path)\n",
    "relabels = read_relabels('relabels.csv')\n",
    "\n",
    "X_train, y_train, y_train_box = \\\n",
    "    read_training_images(config.training_images_path, boxes, relabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training data...\n"
     ]
    }
   ],
   "source": [
    "print('Saving training data...')\n",
    "utils.save_array('X_train.bcolz', X_train)\n",
    "utils.save_array('y_train.bcolz', y_train)\n",
    "utils.save_array('y_train_box.bcolz', y_train_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training data...\n",
      "100 items in 27.17373 seconds\n",
      "100 items in 27.26481 seconds\n",
      "100 items in 27.65015 seconds\n",
      "100 items in 27.71538 seconds\n",
      "100 items in 28.05418 seconds\n",
      "100 items in 27.96163 seconds\n",
      "100 items in 27.79634 seconds\n",
      "100 items in 27.82390 seconds\n",
      "100 items in 27.88686 seconds\n",
      "100 items in 27.83264 seconds\n",
      "100 items in 27.53073 seconds\n",
      "100 items in 27.79231 seconds\n",
      "100 items in 23.40769 seconds\n",
      "100 items in 23.79055 seconds\n",
      "100 items in 24.21567 seconds\n",
      "100 items in 24.96522 seconds\n",
      "100 items in 25.84347 seconds\n",
      "100 items in 27.31962 seconds\n",
      "100 items in 28.18462 seconds\n",
      "100 items in 27.55031 seconds\n",
      "100 items in 28.01662 seconds\n",
      "100 items in 28.57741 seconds\n",
      "100 items in 29.08917 seconds\n",
      "100 items in 28.80423 seconds\n",
      "100 items in 28.74994 seconds\n",
      "100 items in 28.68003 seconds\n",
      "100 items in 29.11735 seconds\n",
      "100 items in 28.92473 seconds\n",
      "100 items in 28.75981 seconds\n",
      "100 items in 28.26348 seconds\n",
      "100 items in 27.39495 seconds\n",
      "100 items in 27.84894 seconds\n",
      "100 items in 27.14360 seconds\n",
      "100 items in 26.45197 seconds\n",
      "100 items in 25.56108 seconds\n",
      "100 items in 24.83482 seconds\n",
      "59 items in 11.65605 seconds\n",
      "100 items in 17.43512 seconds\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('Augmenting training data...')\n",
    "# extend training set\n",
    "factor = 5\n",
    "rotation_range = 2 * np.pi\n",
    "x_scale_range = 1.2\n",
    "y_scale_range = 1.2\n",
    "translation_range = 50\n",
    "\n",
    "n = len(X_train)\n",
    "total = n * factor\n",
    "cnt = 0\n",
    "last_percent = 0\n",
    "batch_size = 100\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "def phelper(X, y, y_box):\n",
    "    X_result = []\n",
    "    y_result = []\n",
    "    y_box_result = []\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for i in range(len(X)):\n",
    "        c = y[i]\n",
    "        for k in range(factor):\n",
    "            img, a_bb, r_bb = box_zoom_rotate_translate(X[i],\n",
    "                                                        y_box[i],\n",
    "                                                        x_scale_range,\n",
    "                                                        y_scale_range,\n",
    "                                                        rotation_range,\n",
    "                                                        translation_range)            \n",
    "            X_result.append(img)\n",
    "            y_result.append(c)\n",
    "            y_box_result.append(a_bb)\n",
    "    t1 = time.time()\n",
    "    print('{} items in {:.5f} seconds'.format(len(X), t1 - t0))\n",
    "    return (X_result, y_result, y_box_result)\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=num_cores)(delayed(phelper)(X_train[i:i + batch_size], y_train[i:i + batch_size], y_train_box[i:i + batch_size]) for i in range(0, len(X_train), batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch processed 0\n",
      "batch processed 1\n",
      "batch processed 2\n",
      "batch processed 3\n",
      "batch processed 4\n",
      "batch processed 5\n",
      "batch processed 6\n",
      "batch processed 7\n",
      "batch processed 8\n",
      "batch processed 9\n",
      "batch processed 10\n",
      "batch processed 11\n",
      "batch processed 12\n",
      "batch processed 13\n",
      "batch processed 14\n",
      "batch processed 15\n",
      "batch processed 16\n",
      "batch processed 17\n",
      "batch processed 18\n",
      "batch processed 19\n",
      "batch processed 20\n",
      "batch processed 21\n",
      "batch processed 22\n",
      "batch processed 23\n",
      "batch processed 24\n",
      "batch processed 25\n",
      "batch processed 26\n",
      "batch processed 27\n",
      "batch processed 28\n",
      "batch processed 29\n",
      "batch processed 30\n",
      "batch processed 31\n",
      "batch processed 32\n",
      "batch processed 33\n",
      "batch processed 34\n",
      "batch processed 35\n",
      "batch processed 36\n",
      "batch processed 37\n",
      "X_train: (22554, 448, 448, 3)\n",
      "y_train: (22554, 8)\n",
      "y_train_box: (22554, 4)\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for batch in results:\n",
    "    X_train = np.append(X_train, batch[0], axis=0)\n",
    "    y_train = np.append(y_train, batch[1], axis=0)\n",
    "    y_train_box = np.append(y_train_box, batch[2], axis=0)\n",
    "    print('batch processed', cnt)\n",
    "    cnt += 1\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_train_box:', y_train_box.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.save_array('X_train_augmented.bcolz', X_train)\n",
    "utils.save_array('y_train_augmented.bcolz', y_train)\n",
    "utils.save_array('y_train_box_augmented.bcolz', y_train_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing data...\n",
      "Reading finished: 31.37 seconds\n",
      "Test data shape: (1000, 448, 448, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test, Id_test = \\\n",
    "    read_testing_images(config.testing_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def create_vgg(w, h):\n",
    "    model = VGG16(include_top=False, weights='imagenet',\n",
    "                  input_tensor=Input(shape=(h, w, 3)))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(X, model, batch_size):\n",
    "    y_pred = []\n",
    "    for batch in range(0, len(X), batch_size):\n",
    "        X_p = preprocess_input(np.asarray(X[i:i+batch_size], dtype=np.float32))\n",
    "        y_pred.extend(model.predict(X_p))\n",
    "    return np.array(y_pred)\n",
    "\n",
    "vgg = create_vgg(config.img_w, config.img_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Preprocessing X_train...')\n",
    "X_train_feat = predict(X_train, vgg, 16)\n",
    "print('Saving..')\n",
    "utils.save_array('X_train_feat.bcolz', X_train_feat)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Preprocessing X_test...')\n",
    "X_test = preprocess_input(X_test)\n",
    "X_test_feat = predict(X_test, vgg, 16)\n",
    "print('Saving..')\n",
    "utils.save_array('X_test_feat.bcolz', X_test_feat)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
